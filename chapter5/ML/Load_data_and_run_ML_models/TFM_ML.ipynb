{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dba1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import time\n",
    "#import math\n",
    "\n",
    "# Sklearn\n",
    "import sklearn\n",
    "# Preprocessor from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "# ANNs from keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout, Dense, LSTM\n",
    "\n",
    "# Import cufflinks for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] =(20,10)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Feature selection\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "# Feature importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#from skpp import ProjectionPursuitRegressor\n",
    "#from skpp import ProjectionPursuitClassifier\n",
    "# # ANNs\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "# Model Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Resample\n",
    "# Block Bootstrap\n",
    "#from arch.bootstrap import StationaryBootstrap\n",
    "# Time Series cross-validation\n",
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Class encoder\n",
    "#from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7290002",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555a8870",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DATA_FRAME_CURATED.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PCALAT~1\\AppData\\Local\\Temp/ipykernel_14844/1308079154.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DATA_FRAME_CURATED.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DATA_FRAME_CURATED.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('DATA_FRAME_CURATED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa042f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc58c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22190666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c94f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Date\"],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd14fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabadf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adcdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({'sign': np.sign(X['Y_next_returns'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(\"Y_next_returns\",1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train/test split\n",
    "split = int(len(X) * 0.7)\n",
    "\n",
    "# We transform Y to a binary classification problem's values (0 y 1)\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "encoder = LabelEncoder() \n",
    "encoder.fit(Y) \n",
    "encoded_Y = encoder.transform(Y) \n",
    "# We transform encoded_Y into a dataframe in order to use .iloc and being able to make the train/test split\n",
    "Y = pd.DataFrame(encoded_Y, columns = ['Column_A'],index=Y.index) \n",
    "\n",
    "# Create train data set\n",
    "# We have to twist the dataset\n",
    "X_train, y_train = X[:split], Y[:split]\n",
    "# Test data after train split\n",
    "# PARA EVITAR CORRELACION ENTRE LAS SERIES PODEMOS TOMAR [SPLIT+3:] ie QUE PREDIGA 3 DIAS ADELANTE DEL TRAIN SET\n",
    "X_test, y_test = X[split:], Y[split:]\n",
    "\n",
    "\n",
    "# Scale the features MinMax for training and test datasets\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "# We change from array to dataframe\n",
    "X_train=pd.DataFrame(scaled_X_train,columns=X.columns,index=X.iloc[:split].index)\n",
    "y_train=pd.DataFrame(y_train,columns=Y.columns,index=Y[:split].index)\n",
    "X_test=pd.DataFrame(scaled_X_test,columns=X.columns,index=X[split:].index)\n",
    "y_test=pd.DataFrame(y_test,columns=Y.columns,index=Y[split:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ff18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad2e10",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67291249",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "start_mnb = time.time()\n",
    "mnb.fit(X_train, y_train)\n",
    "end_mnb = time.time()\n",
    "mnb_runtime=end_mnb - start_mnb\n",
    "\n",
    "print('Runtime:',mnb_runtime)\n",
    "print(\"score on test: %.3f\"  %mnb.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" %mnb.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7095a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(mnb_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce06795",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1424d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=list(mnb.fit(X_train, y_train).coef_[0])\n",
    "max_coef_index=list(np.argsort(coef)[::-1])\n",
    "for i in max_coef_index:\n",
    "    print(list(X_train.columns)[i]+' --> %.3f' %coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57abcac5",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(max_iter=1000)\n",
    "\n",
    "start_lr = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "end_lr = time.time()\n",
    "lr_runtime=end_lr - start_lr\n",
    "\n",
    "print('Runtime:',lr_runtime)\n",
    "print(\"score on test: %.3f\" % lr.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % lr.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da83684",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(lr_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=list(lr.fit(X_train, y_train).coef_[0])\n",
    "max_coef_index=list(np.argsort(coef)[::-1])\n",
    "for i in max_coef_index:\n",
    "    print(list(X_train.columns)[i]+' --> %.3f' %coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f55b3",
   "metadata": {},
   "source": [
    "# 3. K-nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bbae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "\n",
    "start_knn = time.time()\n",
    "knn.fit(X_train, y_train)\n",
    "end_knn = time.time()\n",
    "knn_runtime=end_knn - start_knn\n",
    "\n",
    "print('Runtime:',knn_runtime)\n",
    "print(\"score on test: %.3f\" % knn.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % knn.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdeb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(knn_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc07823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06e14d67",
   "metadata": {},
   "source": [
    "# 4. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=LinearSVC(C=100)\n",
    "\n",
    "start_svm = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "end_svm = time.time()\n",
    "svm_runtime=end_svm - start_svm\n",
    "\n",
    "print('Runtime:',svm_runtime)\n",
    "print(\"score on test: %.3f\" % svm.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % svm.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979722ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(svm_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d513e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=list(svm.fit(X_train, y_train).coef_[0])\n",
    "max_coef_index=list(np.argsort(coef)[::-1])\n",
    "for i in max_coef_index:\n",
    "    print(list(X_train.columns)[i]+' --> %.3f' %coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f20387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c73349e4",
   "metadata": {},
   "source": [
    "# 5. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "start_clf = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "end_clf = time.time()\n",
    "clf_runtime=end_clf - start_clf\n",
    "\n",
    "print('Runtime:',clf_runtime)\n",
    "print(\"score on test: %.3f\"  % clf.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b11753",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(clf_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=list(clf.fit(X_train, y_train).feature_importances_)\n",
    "max_coef_index=list(np.argsort(coef)[::-1])\n",
    "for i in max_coef_index:\n",
    "    print(list(X_train.columns)[i]+' --> %.3f' %coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb2b4e",
   "metadata": {},
   "source": [
    "# 6. Bagging Decision Tree (Ensemble Learning I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_samples: maximum size 0.5=50% of each sample taken from the full dataset\n",
    "# max_features: maximum of features 1=100% taken here all 10K \n",
    "# n_estimators: number of decision trees \n",
    "bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "\n",
    "start_bg = time.time()\n",
    "bg.fit(X_train, y_train)\n",
    "end_bg = time.time()\n",
    "bg_runtime=end_bg - start_bg\n",
    "\n",
    "print('Runtime:',bg_runtime)\n",
    "print(\"score on test: %.3f\" % bg.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % bg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92afcda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(bg_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb810350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3478e87",
   "metadata": {},
   "source": [
    "# 7. Boosting Decision Tree (Ensemble Learning II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),n_estimators=10,learning_rate=0.6)\n",
    "\n",
    "start_adb = time.time()\n",
    "adb.fit(X_train, y_train)\n",
    "end_adb = time.time()\n",
    "adb_runtime=end_adb - start_adb\n",
    "\n",
    "print('Runtime:',adb_runtime)\n",
    "print(\"score on test: %.3f\" % adb.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % adb.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19468289",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=list(adb.fit(X_train, y_train).feature_importances_)\n",
    "max_coef_index=list(np.argsort(coef)[::-1])\n",
    "for i in max_coef_index:\n",
    "    print(list(X_train.columns)[i]+' --> %.3f' %coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905f106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e48343e",
   "metadata": {},
   "source": [
    "# 8. Random Forest (Ensemble Learning III)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae48ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators = number of decision trees\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=9)\n",
    "\n",
    "start_rf = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end_rf = time.time()\n",
    "rf_runtime=end_rf - start_rf\n",
    "\n",
    "print('Runtime:',rf_runtime)\n",
    "print(\"score on test: %.3f\" % rf.score(X_test, y_test))\n",
    "print(\"score on train: %.3f\" % rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(rf_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=list(rf.fit(X_train, y_train).feature_importances_)\n",
    "max_coef_index=list(np.argsort(coef)[::-1])\n",
    "for i in max_coef_index:\n",
    "    print(list(X_train.columns)[i]+' --> %.3f' %coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb92142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "691fa555",
   "metadata": {},
   "source": [
    "# 11. Redes neuronales y Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65cfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP: mirar https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/ + https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "# define model\n",
    "\n",
    "def model_MLP(optimizer,activation,loss,metrics):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(64,  activation = activation))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "MLP=model_MLP(optimizer='adam',activation='relu',loss='binary_crossentropy',metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_MLP = time.time()\n",
    "history_MLP=MLP.fit(X_train, y_train, batch_size=1, epochs=100, verbose=0, validation_split=0.33, shuffle=False)\n",
    "end_MLP = time.time()\n",
    "MLP_runtime=end_MLP - start_MLP\n",
    "\n",
    "print('Runtime:',MLP_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f43e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(MLP_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28cf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MLP.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3097eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.suptitle('MLP model training performance', fontsize=20)\n",
    "axs[0].plot(history_MLP.history['binary_accuracy'])\n",
    "axs[0].plot(history_MLP.history['val_binary_accuracy'])\n",
    "axs[0].set_title('Model accuracy', fontsize=15)\n",
    "axs[0].set_ylabel('binary_accuracy')\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].legend(['train', 'validation'], loc='upper left')\n",
    "axs[1].plot(history_MLP.history['loss'])\n",
    "axs[1].plot(history_MLP.history['val_loss'])\n",
    "axs[1].set_title('Model loss', fontsize=15)\n",
    "axs[1].set_ylabel('loss')\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89851d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "results_MLP=MLP.evaluate(X_train, y_train)\n",
    "print('MLP: [binary_crossentropy, binary_accuracy] =', results_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "results_MLP=MLP.evaluate(X_test, y_test)\n",
    "print('MLP: [binary_crossentropy, binary_accuracy] =', results_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31df46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6a803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "292d374d",
   "metadata": {},
   "source": [
    "# 12. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01741971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the Data for LSTM\n",
    "# reshaping into 3D Array\n",
    "X_train_LSTM=np.array(scaled_X_train).reshape(len(scaled_X_train),1,len(list(X.keys()))) # len(scaled_train_data) samples; 1 timesteps per sample; 9 features per timestep or 1 samples; len(scaled_train_data) timesteps; 9 features per timestep?\n",
    "X_test_LSTM=np.array(scaled_X_test).reshape(len(scaled_X_test),1,len(list(X.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed281e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdcbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM_(optimizer,activation,loss,metrics):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units=256, input_shape = (X_train_LSTM.shape[1],X_train_LSTM.shape[2]), return_sequences=True)) \n",
    "    model.add(Dropout(0.4, seed=seed_value))\n",
    "\n",
    "    model.add(LSTM(units=256, return_sequences=True))\n",
    "    model.add(Dropout(0.4, seed=seed_value))\n",
    "\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.4, seed=seed_value))\n",
    "\n",
    "    model.add(Dense(64,  activation = activation))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the Model\n",
    "model_LSTM=model_LSTM_(optimizer='adam',activation='relu',loss='binary_crossentropy',metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcafdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_LSTM = time.time()\n",
    "history_LSTM=model_LSTM.fit(X_train_LSTM, y_train, batch_size=len(X_train_LSTM), epochs=200, verbose=0, validation_split=0.33, shuffle=False)\n",
    "end_LSTM = time.time()\n",
    "LSTM_runtime=end_LSTM - start_LSTM\n",
    "\n",
    "print('Runtime:',LSTM_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes.append(LSTM_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_LSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.suptitle('LSTM model training performance', fontsize=20)\n",
    "axs[0].plot(history_LSTM.history['binary_accuracy'])\n",
    "axs[0].plot(history_LSTM.history['val_binary_accuracy'])\n",
    "axs[0].set_title('Model accuracy', fontsize=15)\n",
    "axs[0].set_ylabel('binary_accuracy')\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].legend(['train', 'validation'], loc='upper left')\n",
    "axs[1].plot(history_LSTM.history['loss'])\n",
    "axs[1].plot(history_LSTM.history['val_loss'])\n",
    "axs[1].set_title('Model loss', fontsize=15)\n",
    "axs[1].set_ylabel('loss')\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "results_LSTM=model_LSTM.evaluate(X_train_LSTM, y_train)\n",
    "print('LSTM: [binary_crossentropy, binary_accuracy] =', results_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "results_LSTM=model_LSTM.evaluate(X_test_LSTM, y_test)\n",
    "print('LSTM: [binary_crossentropy, binary_accuracy] =', results_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc34c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
